# ğŸš¢ Titanic Survival Prediction - Kaggle Project

This project is a machine learning pipeline to predict survival outcomes on the Titanic dataset provided by Kaggle. The goal is to apply data preprocessing, feature engineering, and classification algorithms to predict which passengers survived the disaster.

---

## ğŸ“‚ Project Overview

This repository contains a Jupyter Notebook that walks through the full data science process:

1. ğŸ“¥ Load and explore the dataset  
2. ğŸ§¹ Clean and preprocess data  
3. ğŸ› ï¸ Engineer useful features  
4. ğŸ¤– Train a logistic regression model  
5. ğŸ“Š Evaluate performance  
6. ğŸ“¤ Generate predictions for Kaggle submission

---

## ğŸ“‘ Dataset

The dataset comes from the [Titanic - Machine Learning from Disaster](https://www.kaggle.com/competitions/titanic/) competition on Kaggle.

Files used:
- `train.csv` - training set with labels
- `test.csv` - test set (for submission)

---

## âš™ï¸ Methods Used

### ğŸ“Š Data Preprocessing

- Filled missing values (`Age`, `Embarked`)
- Removed non-informative columns: `Cabin`, `Ticket`, `Name`
- Converted categorical columns (`Sex`, `Embarked`) to numeric using `get_dummies`
- Created new features like:
  - `FamilySize` = `SibSp` + `Parch` + 1
  - `IsAlone` = (`FamilySize` == 1)

### ğŸ¤– Model Training

- **Logistic Regression** via `scikit-learn`
- Data split: 80% training, 20% validation (`train_test_split`)
- Model evaluated using **accuracy score**

### ğŸ§ª Evaluation

- Used accuracy metric to measure performance
- Cross-validation or advanced metrics (e.g., confusion matrix, ROC) can be added as extensions

---

## ğŸš€ Getting Started

### ğŸ”§ Requirements

- Python 3.x
- Jupyter Notebook
- `pandas`, `numpy`, `matplotlib`, `seaborn`, `sklearn`

External dataset URL:(https://www.kaggle.com/datasets/heptapod/titanic)
